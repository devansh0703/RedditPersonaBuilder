#!/usr/bin/env python3
"""
Reddit Persona Generator

A script that scrapes Reddit user profiles and generates detailed user personas
with AI analysis and citation support.

Usage:
    python reddit_persona_generator.py <reddit_user_url>
    python reddit_persona_generator.py https://www.reddit.com/user/username/

Requirements:
    - Reddit API credentials (REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET)
    - Gemini API key (GEMINI_API_KEY)
"""

import argparse
import logging
import os
import sys
from datetime import datetime
from typing import Dict, Any

from config import OUTPUT_DIR
from reddit_scraper import RedditScraper
from persona_analyzer import PersonaAnalyzer
from utils import (
    extract_username_from_url, 
    sanitize_filename, 
    create_output_directory,
    validate_reddit_data,
    format_timestamp
)


def setup_logging():
    """Set up logging configuration."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('reddit_persona_generator.log')
        ]
    )


def format_persona_output(username: str, persona: Dict[str, Any], citations: Dict[str, Any], reddit_data: Dict[str, Any]) -> str:
    """Format persona data into readable text output."""
    profile = reddit_data['profile']
    stats = reddit_data['statistics']
    
    output = f"""
{'='*80}
REDDIT USER PERSONA ANALYSIS
{'='*80}

USERNAME: {username}
GENERATED ON: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ACCOUNT CREATED: {format_timestamp(profile['created_utc'])}
ACCOUNT AGE: {profile['account_age_days']:.0f} days
KARMA: {profile['comment_karma']} comment / {profile['link_karma']} link
TOTAL ACTIVITY: {stats['total_posts']} posts, {stats['total_comments']} comments

{'='*80}
DEMOGRAPHICS
{'='*80}

AGE ESTIMATE: {persona['demographics']['age_estimate']}

OCCUPATION GUESS: {persona['demographics']['occupation_guess']}

LOCATION HINTS: {persona['demographics']['location_hints']}

LIFESTYLE: {persona['demographics']['lifestyle']}

SUPPORTING EVIDENCE:
{chr(10).join([f"• {citation}" for citation in citations.get('demographics', [])])}

{'='*80}
BEHAVIOR & HABITS
{'='*80}

POSTING PATTERNS: {persona['behavior_habits']['posting_patterns']}

INTERACTION STYLE: {persona['behavior_habits']['interaction_style']}

CONTENT PREFERENCES: {persona['behavior_habits']['content_preferences']}

ACTIVITY LEVEL: {persona['behavior_habits']['activity_level']}

SUPPORTING EVIDENCE:
{chr(10).join([f"• {citation}" for citation in citations.get('behavior_habits', [])])}

{'='*80}
MOTIVATIONS
{'='*80}

PRIMARY DRIVERS: {persona['motivations']['primary_drivers']}

VALUES: {persona['motivations']['values']}

INTERESTS: {persona['motivations']['interests']}

SUPPORTING EVIDENCE:
{chr(10).join([f"• {citation}" for citation in citations.get('motivations', [])])}

{'='*80}
PERSONALITY TRAITS
{'='*80}

INTROVERSION/EXTROVERSION: {persona['personality']['introversion_extroversion']}

THINKING/FEELING: {persona['personality']['thinking_feeling']}

JUDGING/PERCEIVING: {persona['personality']['judging_perceiving']}

COMMUNICATION STYLE: {persona['personality']['communication_style']}

SUPPORTING EVIDENCE:
{chr(10).join([f"• {citation}" for citation in citations.get('personality', [])])}

{'='*80}
GOALS & NEEDS
{'='*80}

PRIMARY GOALS: {persona['goals_needs']['primary_goals']}

INFORMATION NEEDS: {persona['goals_needs']['information_needs']}

SOCIAL NEEDS: {persona['goals_needs']['social_needs']}

SUPPORTING EVIDENCE:
{chr(10).join([f"• {citation}" for citation in citations.get('goals_needs', [])])}

{'='*80}
FRUSTRATIONS
{'='*80}

MAIN FRUSTRATIONS: {persona['frustrations']['main_frustrations']}

PAIN POINTS: {persona['frustrations']['pain_points']}

CHALLENGES: {persona['frustrations']['challenges']}

SUPPORTING EVIDENCE:
{chr(10).join([f"• {citation}" for citation in citations.get('frustrations', [])])}

{'='*80}
TOP SUBREDDITS
{'='*80}

{chr(10).join([f"r/{subreddit}: {count} activities" for subreddit, count in stats['top_subreddits']])}

{'='*80}
ANALYSIS COMPLETE
{'='*80}

This persona was generated by analyzing {stats['total_posts']} posts and {stats['total_comments']} comments
from Reddit user u/{username}. The analysis is based on publicly available content and should be
considered an interpretation of online behavior patterns.

Generated by Reddit Persona Generator v1.0
"""
    
    return output


def save_persona_to_file(username: str, persona_text: str) -> str:
    """Save persona text to file and return filename."""
    create_output_directory(OUTPUT_DIR)
    
    # Create filename
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"{sanitize_filename(username)}_persona_{timestamp}.txt"
    filepath = os.path.join(OUTPUT_DIR, filename)
    
    # Save to file
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(persona_text)
    
    return filepath


def main():
    """Main function to run the Reddit persona generator."""
    parser = argparse.ArgumentParser(
        description='Generate detailed user personas from Reddit profiles',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python reddit_persona_generator.py https://www.reddit.com/user/username/
    python reddit_persona_generator.py https://www.reddit.com/u/username/
        """
    )
    
    parser.add_argument(
        'reddit_url',
        help='Reddit user profile URL'
    )
    
    parser.add_argument(
        '--output-dir',
        default=OUTPUT_DIR,
        help=f'Output directory for persona files (default: {OUTPUT_DIR})'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Enable verbose logging'
    )
    
    args = parser.parse_args()
    
    # Setup logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    setup_logging()
    
    try:
        # Extract username from URL
        logging.info(f"Extracting username from URL: {args.reddit_url}")
        username = extract_username_from_url(args.reddit_url)
        logging.info(f"Target username: {username}")
        
        # Initialize scraper and analyzer
        logging.info("Initializing Reddit scraper...")
        scraper = RedditScraper()
        
        logging.info("Initializing persona analyzer...")
        analyzer = PersonaAnalyzer()
        
        # Scrape Reddit data
        logging.info(f"Scraping Reddit data for user: {username}")
        reddit_data = scraper.scrape_user_data(username)
        
        if not validate_reddit_data(reddit_data):
            raise ValueError("Invalid Reddit data structure")
        
        logging.info(f"Successfully scraped {reddit_data['statistics']['total_activity']} total activities")
        
        # Generate persona
        logging.info("Generating AI persona analysis...")
        try:
            persona = analyzer.generate_persona(reddit_data)
            logging.info("Successfully generated persona")
        except Exception as e:
            logging.error(f"Failed to generate persona: {e}")
            raise
        
        # Generate citations
        logging.info("Generating citations...")
        try:
            citations = analyzer.generate_citations(reddit_data, persona)
            logging.info("Successfully generated citations")
        except Exception as e:
            logging.warning(f"Failed to generate citations: {e}")
            # Continue with empty citations if citation generation fails
            citations = {}
        
        # Format output
        logging.info("Formatting persona output...")
        persona_text = format_persona_output(username, persona, citations, reddit_data)
        
        # Save to file
        logging.info("Saving persona to file...")
        filepath = save_persona_to_file(username, persona_text)
        
        # Success message
        print(f"\n{'='*60}")
        print("PERSONA GENERATION COMPLETE!")
        print(f"{'='*60}")
        print(f"Username: {username}")
        print(f"Output file: {filepath}")
        print(f"Total activities analyzed: {reddit_data['statistics']['total_activity']}")
        print(f"Analysis timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")
        
        # Print summary to console
        print("\nPERSONA SUMMARY:")
        print("-" * 40)
        print(f"Age Estimate: {persona['demographics']['age_estimate']}")
        print(f"Occupation Guess: {persona['demographics']['occupation_guess']}")
        print(f"Top Interests: {persona['motivations']['interests']}")
        print(f"Communication Style: {persona['personality']['communication_style']}")
        print(f"Primary Goals: {persona['goals_needs']['primary_goals']}")
        print(f"Main Frustrations: {persona['frustrations']['main_frustrations']}")
        
        print(f"\nFull detailed analysis saved to: {filepath}")
        
    except KeyboardInterrupt:
        logging.info("Process interrupted by user")
        sys.exit(1)
    except Exception as e:
        logging.error(f"Error generating persona: {e}")
        print(f"\nERROR: {e}")
        print("\nPlease check:")
        print("1. Reddit API credentials are set (REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET)")
        print("2. Gemini API key is set (GEMINI_API_KEY)")
        print("3. The Reddit user profile URL is valid and public")
        print("4. You have internet connection")
        sys.exit(1)


if __name__ == "__main__":
    main()
